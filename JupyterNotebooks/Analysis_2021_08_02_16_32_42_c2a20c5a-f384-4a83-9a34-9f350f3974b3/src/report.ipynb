{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "914f9b1c",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "Describe the module blabla\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ef733a",
   "metadata": {},
   "source": [
    "## T-Test\n",
    "\n",
    "Explain the test labla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ee000",
   "metadata": {},
   "outputs": [],
   "source": [
    "        import modules.adapml_data as adapml_data\n",
    "        import modules.adapml_classification as adapml_classification\n",
    "        import modules.adapml_clustering as adapml_clustering\n",
    "        import modules.adapml_chemometrics as adapml_chemometrics\n",
    "        import modules.adapml_statistics as adapml_statistics\n",
    "        import modules.adapml_regression as adapml_regression\n",
    "        import numpy as np\n",
    "        import modules.loadTestData as load_data\n",
    "        import sklearn.preprocessing as pre\n",
    "        from sklearn.cross_decomposition import PLSRegression as PLS\n",
    "        from matplotlib import pyplot as plt\n",
    "        from sklearn import cluster as clst\n",
    "        from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "        import os\n",
    "\n",
    "        reldir = os.getcwd()\n",
    "        path_to_data = os.path.join(reldir, '..', 'data', 'SCLC_study_output_filtered_2.csv')\n",
    "\n",
    "        data = adapml_data.DataImport(path_to_data)\n",
    "\n",
    "        response1D = data.resp\n",
    "        #response1D = adapml_data.DataImport.getResponse(path_to_data)\n",
    "        response2D = adapml_data.DataImport.getDummyResponse(response1D)\n",
    "\n",
    "        variables = data.getVariableNames()\n",
    "        samples = data.getSampleNames()\n",
    "\n",
    "        t_test = adapml_statistics.Statistics(data.data, 'anova', response1D)\n",
    "        t_test.plot_logp_values(variables)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93303505",
   "metadata": {},
   "source": [
    "## Volcano Plot\n",
    "\n",
    "blabla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a829495",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test.plot_volcano_t(variables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00c894",
   "metadata": {},
   "source": [
    "# Dimension-Reduction\n",
    "\n",
    "Dimension-reduction methods are used to condense high dimensional data down to dimensions which provide the most information. We have implemented the principal component analysis (PCA). It performs a change of basis and the new basis is chosen, such that the i-th principal component is orthogonal to the first i-1 principal components and the direction maximizes the variance of the projected data.\n",
    "We use the Python library sklearn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589493a",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "The principal component analysis (PCA) is one of the methods for dimension-reduction. It performs a change of basis and the new basis is chosen, such that the i-th principal component is orthogonal to the first i-1 principal components and the direction maximizes the variance of the projected data. Instead of considering all the dimensions,\n",
    "we pick the necessary number of principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a03fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.normalizeData(\"autoscale\")\n",
    "\n",
    "pca = adapml_chemometrics.Chemometrics(data.data, \"pca\", response1D)\n",
    "\n",
    "print(\"PCA Projections\");pca.plotProjectionScatterMultiClass(2, labels=[\"Healthy\", \"Not Healthy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bcd6ff",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis\n",
    "bla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c81524",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = adapml_chemometrics.Chemometrics(data.data, \"lda\", response1D) # Also Predicts\n",
    "\n",
    "print(\"LDA Projections\");lda.plotProjectionScatterMultiClass(1, labels=[\"Healthy\", \"Not Healthy\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d712e42",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440e0c4a",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dbe3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_cluster = adapml_clustering.Clustering(data.data, 'kmeans', 3)\n",
    "kmeans_cluster.getClusterResults(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8f56d",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d05a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchical_cluster = adapml_clustering.Clustering(data.data, 'hierarchical', 3)\n",
    "hierarchical_cluster.getClusterResults(samples)\n",
    "hierarchical_cluster.plot_dendrogram(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cd7ff8",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907556c3",
   "metadata": {},
   "source": [
    "## Partial Least Squares-Discriminant Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda988e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotProjectionScatterMultiClass(pc, resp, num_var):\n",
    "    plt.figure(figsize=(24, 18))\n",
    "\n",
    "    for i in range(num_var):\n",
    "        for j in range(num_var):\n",
    "            plt.subplot(5,5,5*(i) + j + 1)\n",
    "            for c in range(resp.shape[1]):\n",
    "                inx = np.where(resp[:,c] == 1)[0]\n",
    "                tmp = pc[inx,:]\n",
    "                pc1 = tmp[:,i]\n",
    "                pc2 = tmp[:,j]\n",
    "                plt.scatter(pc1, pc2)\n",
    "            plt.xlabel(\"PLS Component \"+str(i+1))\n",
    "            plt.ylabel(\"PLS Component \"+str(j+1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "data = load_data.loadDataPandas(path_to_data)\n",
    "d = data.to_numpy()\n",
    "var_index = data.columns.values.tolist()\n",
    "\n",
    "resp = load_data.getResponseMatrix2D()\n",
    "\n",
    "norm_trans = pre.StandardScaler().fit(d)\n",
    "data_norm = norm_trans.transform(d)\n",
    "#data_norm, norm_trans = pre.mean_center(d)\n",
    "#In-built preprocessing method - TBD\n",
    "\n",
    "pls = PLS().fit(data_norm, resp)\n",
    "pls_trans = pls.transform(data_norm)\n",
    "\n",
    "plotProjectionScatterMultiClass(pls_trans, resp, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55408269",
   "metadata": {},
   "source": [
    "## Support Vector Machines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10612ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = adapml_data.DataImport(path_to_data)\n",
    "svm = adapml_classification.Classification(data.data, response1D, 'svm', .75, kfolds=3)\n",
    "\n",
    "adapml_classification.print_model_stats(svm, \"SVM\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ac2fd",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fb3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = adapml_data.DataImport(path_to_data)\n",
    "rnf = adapml_classification.Classification(data.data, response1D, 'randomforest', .75, kfolds=3)\n",
    "\n",
    "adapml_classification.print_model_stats(rnf, \"RF\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c62fa00",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9512a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = adapml_data.DataImport(path_to_data)\n",
    "\n",
    "logistic = adapml_classification.Classification(data.data, response1D, 'logistic', .25)\n",
    "print(logistic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb085df3",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6046506e",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d1035",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = adapml_regression.Regression(data.data, \"linear\")\n",
    "reg.linear\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
